{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/labs/lab07data/DO_record_per_line.json'\n",
    "df = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|\n",
      "|  14/social_sciences|We live in a digi...|  7|  en|Becoming a Dynami...|Canvas Network|\n",
      "|2/biology_life_sc...|This self-paced c...|  8|  en|           Bioethics|Canvas Network|\n",
      "|9/humanities|15/m...|This game-based c...|  9|  en|College Foundatio...|Canvas Network|\n",
      "|  14/social_sciences|What’s in your di...| 10|  en|Digital Literacies I|Canvas Network|\n",
      "|  14/social_sciences|The goal of the D...| 11|  en|Digital Literacie...|Canvas Network|\n",
      "|  14/social_sciences|Ready to explore ...| 12|  en|Digital Tools for...|Canvas Network|\n",
      "|  14/social_sciences|This self-paced c...| 13|  en|Discover Your Val...|Canvas Network|\n",
      "|  12/medicine_health|What is “interpro...| 14|  en|Enhancing Patient...|Canvas Network|\n",
      "|        16/languages|This course prese...| 15|  en|Ethics and Values...|Canvas Network|\n",
      "|         4/chemistry|Chemistry is an i...| 16|  en| Exploring Chemistry|Canvas Network|\n",
      "|8/engineering_tec...|Are you consideri...| 17|  en|Exploring Enginee...|Canvas Network|\n",
      "|   1/arts_music_film|Princess stories ...| 18|  en|Fairy Tales: Orig...|Canvas Network|\n",
      "|        9/humanities|This first instal...| 19|  en|First Peoples to ...|Canvas Network|\n",
      "|  14/social_sciences|This course exami...| 20|  en| Forums for a Future|Canvas Network|\n",
      "|        9/humanities|This course will ...| 21|  en|From the Gilded A...|Canvas Network|\n",
      "|8/engineering_tec...|The field of tech...| 22|  en|Fundamentals of S...|Canvas Network|\n",
      "|  14/social_sciences|Are you a Higher ...| 23|  en|Hybrid Courses: B...|Canvas Network|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('lang').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|lang|count|\n",
      "+----+-----+\n",
      "|  en|24553|\n",
      "|  vi|    1|\n",
      "|  nb|    2|\n",
      "|  uz|    1|\n",
      "|  ur|   11|\n",
      "|  pl|    1|\n",
      "|  sk|    5|\n",
      "|  pt|  187|\n",
      "|  sw|    1|\n",
      "|  ko|    3|\n",
      "|  ms|    1|\n",
      "|  tr|  120|\n",
      "|  de|  166|\n",
      "|  es| 1374|\n",
      "|  hr|    4|\n",
      "|  el|    5|\n",
      "|  it|   62|\n",
      "|  af|    2|\n",
      "|  ar|   34|\n",
      "|  sv|    1|\n",
      "|  nl|    6|\n",
      "|  hu|    2|\n",
      "|  ca|    6|\n",
      "|  ru| 1231|\n",
      "|  fa|    1|\n",
      "|  bg|    2|\n",
      "|  hi|    6|\n",
      "|  et|    1|\n",
      "|  zh|  169|\n",
      "|  fr|  104|\n",
      "|  ja|   77|\n",
      "|  id|    1|\n",
      "|  da|    3|\n",
      "|  fi|    2|\n",
      "|  he|    8|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('lang').count().show(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.lang.isin(['en', 'es', 'ru'])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.68 µs\n",
      "+----+-----+\n",
      "|lang|count|\n",
      "+----+-----+\n",
      "|  en|24553|\n",
      "|  es| 1374|\n",
      "|  ru| 1231|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df.groupby('lang').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переводим данные в pd.DatsFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_df = pd.DataFrame(df.filter(df['lang'] == 'ru').select('id', 'name', 'lang', 'desc').sort(\"name\").take(1231), columns=['id', 'name', 'lang', 'desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_df = pd.DataFrame(df.filter(df['lang'] == 'es').select('id', 'name', 'lang', 'desc').sort(\"name\").take(1374), columns=['id', 'name', 'lang', 'desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.DataFrame(df.filter(df['lang'] == 'en').select('id', 'name', 'lang', 'desc').sort(\"name\").take(24553), columns=['id', 'name', 'lang', 'desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id      24553\n",
      "name    24553\n",
      "lang    24553\n",
      "desc    24553\n",
      "dtype: int64 id      1374\n",
      "name    1374\n",
      "lang    1374\n",
      "desc    1374\n",
      "dtype: int64 id      1231\n",
      "name    1231\n",
      "lang    1231\n",
      "desc    1231\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (en_df.count(), es_df.count(), ru_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_list_id = ru_df['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1231"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru_list_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем списки из текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_list(df):\n",
    "    texts = []\n",
    "    for el in df.desc:\n",
    "        texts.append(el)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.78 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "ru_text = text_list(ru_df)\n",
    "es_text = text_list(es_df)\n",
    "en_text = text_list(en_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231 1374 24553\n"
     ]
    }
   ],
   "source": [
    "print (len(ru_text), len(es_text), len(en_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пробуем различные лематизаторы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(r'[\\w\\d]{2,}', re.U) # пробуем токенизацию, представленную в лабе\n",
    "def tokenizer_(text):\n",
    "    return regex.findall(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re        # пробуем токенизацию из прошлых лекций для русского языка  (pymorphy)\n",
    "GROUPING_SPACE_REGEX = re.compile(r'([^\\w]|[+])', re.UNICODE)\n",
    "def simple_word_tokenize(text, _split=GROUPING_SPACE_REGEX.split):\n",
    "    return [t for t in _split(text.lower()) if t and not t.isspace()]\n",
    "\n",
    "import pymorphy2\n",
    "m = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def token_r(text):\n",
    "    words = simple_word_tokenize(text)\n",
    "    return [m.parse(x)[0].normal_form for x in words if len(x)>=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_russian = token_r(ru_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['курс',\n",
       " 'рассказываться',\n",
       " 'продвинуть',\n",
       " 'advanced',\n",
       " 'алгоритм',\n",
       " 'для',\n",
       " 'школьник',\n",
       " 'этот',\n",
       " 'курс',\n",
       " 'читаться',\n",
       " 'на',\n",
       " 'летний',\n",
       " 'компьютерный',\n",
       " 'школа',\n",
       " 'для',\n",
       " 'участник',\n",
       " 'олимпиада',\n",
       " 'по',\n",
       " 'информатика']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_russian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразовываем тексты в вектора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ru_df = ru_df[ru_df['id'].isin([1056, 1421])]\n",
    "id_ru_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ru_text = text_list(id_ru_df)\n",
    "id_ru_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1231\n"
     ]
    }
   ],
   "source": [
    "print (len(id_ru_text), len(ru_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232\n"
     ]
    }
   ],
   "source": [
    "ru_text982 = ru_text.copy()\n",
    "ru_text982.append(id_ru_text[0])\n",
    "print (len(ru_text982))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232\n"
     ]
    }
   ],
   "source": [
    "ru_text12201 = ru_text.copy()\n",
    "ru_text12201.append(id_ru_text[1])\n",
    "print (len(ru_text12201))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1232, 10000)\n"
     ]
    }
   ],
   "source": [
    "hcv = HashingVectorizer(tokenizer = token_r, n_features=10000)\n",
    "ru_matrix982 = hcv.fit_transform(ru_text982)\n",
    "print(ru_matrix982.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1232, 10000)\n"
     ]
    }
   ],
   "source": [
    "ru_matrix12201 = hcv.fit_transform(ru_text12201)\n",
    "print(ru_matrix12201.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def matrix_to_dict(matrix, df, id_):\n",
    "    cos_m = cosine_similarity(matrix[-1], matrix[:1231])\n",
    "    cos_list = []\n",
    "    for i in cos_m:\n",
    "        for j in i:\n",
    "            cos_list.append(j)\n",
    "    list_id = df['id'].tolist()\n",
    "    dict_ = dict(zip(list_id, cos_list))\n",
    "    c = Counter(dict_)\n",
    "    cnt = 0\n",
    "    for i in sorted(c, key=c.get, reverse=True):\n",
    "        cnt = cnt+1\n",
    "        if cnt>11:\n",
    "            break\n",
    "        elif cnt>1:\n",
    "            if id_ not in sorted_d.keys():\n",
    "                sorted_d[id_] = [i]\n",
    "            else:\n",
    "                sorted_d[id_].append(i)\n",
    "    return sorted_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = matrix_to_dict(ru_matrix982, ru_df, '982')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = matrix_to_dict(ru_matrix12201, ru_df, '12201')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'982': [1260, 858, 888, 26327, 860, 13701, 22553, 778, 773, 786],\n",
       " '12201': [1236, 18331, 1001, 12725, 1273, 20288, 1252, 1332, 20351, 1365]}"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16487</td>\n",
       "      <td>Aprende cómo crear gráficos en 3D con 3Ds Max ...</td>\n",
       "      <td>es</td>\n",
       "      <td>\\nEn este curso realizaremos el modelado, text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>23487</td>\n",
       "      <td>Esquemas, subtotales y análisis de datos con E...</td>\n",
       "      <td>es</td>\n",
       "      <td>Aprende a utilizar herramientas de análisis d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               name lang  \\\n",
       "196  16487  Aprende cómo crear gráficos en 3D con 3Ds Max ...   es   \n",
       "711  23487  Esquemas, subtotales y análisis de datos con E...   es   \n",
       "\n",
       "                                                  desc  \n",
       "196  \\nEn este curso realizaremos el modelado, text...  \n",
       "711   Aprende a utilizar herramientas de análisis d...  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_es_df = es_df[es_df['id'].isin([16487, 23487])]\n",
    "id_es_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nEn este curso realizaremos el modelado, texturizado, iluminación y render de una grifería de estilo clásico, consiguiendo un aspecto final hiperrealista de nuestra escena con 3Ds Max y Vray.\\n3dsMax es un programa de creación de gráficos y animación 3D desarrollado por Autodesk, en concreto la división Autodesk Media &amp; Entertainment (anteriormente Discreet). Creado inicialmente por el Grupo Yost para Autodesk, salió a la venta por primera vez en 1990 para DOS. 3ds Max, con su arquitectura basada en plugins, es uno de los programas de animación 3D más utilizado, especialmente para la creación de video juegos, anuncios de televisión, en arquitectura o en películas. Este curso es impartido por Daniel Bertó, dedicado a mundo del 3D desde hace más de diez años, dentro de su curriculum académico podemos destacar, un Master en Infoarquitectura, un Master en Modelado y Animación de personajes, un Master en Mudbox, así como la Carrera de Dirección de Cine Digital y efectos especiales THX. Su experiencia laboral comienza en el campo de la infoarquitectura , y posteriormente en la publicidad, los videojuegos y la dirección de un Teaser Trailer en 3D, donde dirigió un equipo de once personas y en el que coordinó los departamentos de modelado, texturizado, iluminación y render. Category:\\nTechnology ',\n",
       " ' Aprende a utilizar herramientas de análisis de datos que te ayudan a comprender y interpretar mejor la información. Aprende a sacar provecho de las herramientas de análisis, un complemento de Excel que agrega funciones adicionales al programa y que ayudan en el análisis (Solver, Histograma...) Además, alivia tu trabajo con los esquemas y los subtotales en Excel que te permiten obtener sumas, promedios, productos, máximos, mínimos,...de una serie de datos, de forma automática y resumida. Dominar estas herramientas te permite realizar un análisis de los datos de forma rápida Este curso esta sacado de mi curso completo de Excel 2010, también disponible en Udemy. I. Esquemas y subtotales Crear un esquema manualmente Autoesquema Insertar subtotales II. Análisis de datos Escenarios Combinar escenarios Crear un resumen de escenarios Buscar Objetivo Crear una tabla de datos de 1 variable Crear una tabla de datos de 2 variables Solver Utilizar Solver con restricciones Estadística descriptiva Histograma Muestra What are the requirements? Los estudiantes del curso deben disponer del programa Microsoft Excel 2010 para poder seguir óptimamente el curso. What am I going to get from this course? Over 20 lectures and 29 mins of content! Sacar información de mis datos y facilitar la toma de decisiones. Manejar las herramientas de análisis. Agrupar datos en una hoja. Crear un esquema de filas y columnas. Mostrar u ocultar datos de esquemas. Comprender e interpretar mejor la información con subtotales. Realizar un análisis de los datos de forma rápida realizando agrupaciones. Instalar y activar Herramientas para análisis y Solver. analizar los datos y mostrarlos en un histograma. Definir y resolver un problema con Solver. What is the target audience? Este curso va dirigido a toda persona que quiera potenciar sus habilidades en el uso de hojas de cálculo con Excel, pudiendo presentar trabajos de alta calidad con formato profesional. SECTION 1: Introducción\\nIntroducciónSECTION 2: Esquemas y subtotales\\nObjetivos de la secciónCrear un esquema manualmenteAutoesquemaInsertar subtotalesCaso prácticoPrueba de comprensiónSECTION 3: Análisis de datos\\nObjetivos de la secciónEscenariosCombinar escenariosCrear un resumen de escenariosBuscar ObjetivoCrear una tabla de datos de 1 variableCrear una tabla de datos de 2 variablesSolverUtilizar Solver con restriccionesEstadística descriptivaHistogramaMuestraCaso prácticoPrueba de comprensiónSECTION 4: Conclusión\\nConclusión']"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_es_text = text_list(id_es_df)\n",
    "id_es_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1374\n"
     ]
    }
   ],
   "source": [
    "print (len(id_es_text), len(es_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375\n"
     ]
    }
   ],
   "source": [
    "es_text16487 = es_text.copy()\n",
    "es_text16487.append(id_es_text[0])\n",
    "print (len(es_text16487))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375\n"
     ]
    }
   ],
   "source": [
    "es_text23487 = es_text.copy()\n",
    "es_text23487.append(id_es_text[1])\n",
    "print (len(es_text23487))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1375, 10000)\n"
     ]
    }
   ],
   "source": [
    "hcv = HashingVectorizer(tokenizer = tokenizer_, n_features=10000)\n",
    "es_matrix16487 = hcv.fit_transform(es_text16487)\n",
    "print(es_matrix16487.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1375, 10000)\n"
     ]
    }
   ],
   "source": [
    "es_matrix23487 = hcv.fit_transform(es_text23487)\n",
    "print(es_matrix23487.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def matrix_to_dict(matrix, df, id_):\n",
    "    cos_m = cosine_similarity(matrix[-1], matrix[:1374])\n",
    "    cos_list = []\n",
    "    for i in cos_m:\n",
    "        for j in i:\n",
    "            cos_list.append(j)\n",
    "    list_id = df['id'].tolist()\n",
    "    dict_ = dict(zip(list_id, cos_list))\n",
    "    c = Counter(dict_)\n",
    "    cnt = 0\n",
    "    for i in sorted(c, key=c.get, reverse=True):\n",
    "        cnt = cnt+1\n",
    "        if cnt>11:\n",
    "            break\n",
    "        elif cnt>1:\n",
    "            if id_ not in sorted_d.keys():\n",
    "                sorted_d[id_] = [i]\n",
    "            else:\n",
    "                sorted_d[id_].append(i)\n",
    "    return sorted_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = matrix_to_dict(es_matrix16487, es_df, '16487')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = matrix_to_dict(es_matrix23487, es_df, '23487')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11963</th>\n",
       "      <td>21888</td>\n",
       "      <td>Introduction to Psychology</td>\n",
       "      <td>en</td>\n",
       "      <td>This course is an introduction to psychology, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19249</th>\n",
       "      <td>26707</td>\n",
       "      <td>SQL Server - Real World Troubleshooting Skills...</td>\n",
       "      <td>en</td>\n",
       "      <td>Watch as I use one free tool to diagnose SQL ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               name lang  \\\n",
       "11963  21888                         Introduction to Psychology   en   \n",
       "19249  26707  SQL Server - Real World Troubleshooting Skills...   en   \n",
       "\n",
       "                                                    desc  \n",
       "11963  This course is an introduction to psychology, ...  \n",
       "19249   Watch as I use one free tool to diagnose SQL ...  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_en_df = en_df[en_df['id'].isin([21888, 26707])]\n",
    "id_en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This course is an introduction to psychology, based on classic theory&nbsp; and the latest empirical research, which reviews the basic theory, methods, and research findings of scientific psychology with a strong focus on positive psychology. In this day and age, as the physical quality of life&nbsp; improves, it is particularly important to focus on psychology. In Universities in the United States, psychology is one of the most popular subjects. This course is divided into 13 lessons, an Introduction followed by 12 lessons that focus on: consciousness, sensation, perception, learning, memory, thinking, emotion, evolution, motivation, personality, social psychology, and happiness. In every lesson, the empirical studies of psychology will be given as examples, and classical theoretical perspectives dominate, all of which lead to the culminating perspective of&nbsp; positive psychology. Students will learn about the basic content and frontiers of psychology, and understand psychological modes of thought, while freeing themselves of psychological confusions and misunderstandings. They will master the basic methods of psychological research. ',\n",
       " ' Watch as I use one free tool to diagnose SQL Server problems. ']"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_en_text = text_list(id_en_df)\n",
    "id_en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 24553\n"
     ]
    }
   ],
   "source": [
    "print (len(id_en_text), len(en_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24554\n"
     ]
    }
   ],
   "source": [
    "en_text21888 = en_text.copy()\n",
    "en_text21888.append(id_en_text[0])\n",
    "print (len(en_text21888))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24554\n"
     ]
    }
   ],
   "source": [
    "en_text26707 = en_text.copy()\n",
    "en_text26707.append(id_en_text[1])\n",
    "print (len(en_text26707))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24554, 10000)\n"
     ]
    }
   ],
   "source": [
    "hcv = HashingVectorizer(tokenizer = tokenizer_, n_features=10000, stop_words=stops)\n",
    "en_matrix21888 = hcv.fit_transform(en_text21888)\n",
    "print(en_matrix21888.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24554, 10000)\n"
     ]
    }
   ],
   "source": [
    "en_matrix26707 = hcv.fit_transform(en_text26707)\n",
    "print(en_matrix26707.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_d = {'982': [1260, 858, 888, 26327, 860, 13701, 22553, 778, 773, 786], '12201': [1236, 18331, 1001, 12725, 1273, 20288, 1252, 20351, 1332, 1365], '16487': [12453, 12303, 12339, 12243, 11634, 12336, 11580, 12298, 12338, 12337], '23487': [23506, 22681, 12827, 25902, 18813, 25383, 9409, 3902, 20078, 4714]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def matrix_to_dict(matrix, df, id_):\n",
    "    cos_m = cosine_similarity(matrix[-1], matrix[:24553])\n",
    "    cos_list = []\n",
    "    for i in cos_m:\n",
    "        for j in i:\n",
    "            cos_list.append(j)\n",
    "    list_id = df['id'].tolist()\n",
    "    dict_ = dict(zip(list_id, cos_list))\n",
    "    c = Counter(dict_)\n",
    "    cnt = 0\n",
    "    for i in sorted(c, key=c.get, reverse=True):\n",
    "        cnt = cnt+1\n",
    "        if cnt>11:\n",
    "            break\n",
    "        elif cnt>1:\n",
    "            if id_ not in sorted_d.keys():\n",
    "                sorted_d[id_] = [i]\n",
    "            else:\n",
    "                sorted_d[id_].append(i)\n",
    "    return sorted_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = matrix_to_dict(en_matrix21888, en_df, '21888')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = matrix_to_dict(en_matrix26707, en_df, '26707')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'982': [1260, 858, 888, 26327, 860, 13701, 22553, 778, 773, 786], '12201': [1236, 18331, 1001, 12725, 1273, 20288, 1252, 20351, 1332, 1365], '16487': [12453, 12303, 12339, 12243, 11634, 12336, 11580, 12298, 12338, 12337], '23487': [23506, 22681, 12827, 25902, 18813, 25383, 9409, 3902, 20078, 4714], '21888': [343, 21721, 403, 501, 8301, 396, 17117, 21376, 5631, 19233], '26707': [26910, 26376, 7057, 13524, 13526, 13527, 13528, 19090, 19263, 8132]}\n"
     ]
    }
   ],
   "source": [
    "print (rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('lab07s.json', 'w') as f:\n",
    "    json.dump(rr, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
